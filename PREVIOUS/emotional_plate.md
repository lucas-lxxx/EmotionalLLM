**前提： SER白盒，LLM黑盒。**

**难点**

1. 构建“情绪色轮”与寻找“情绪补色”进行攻击
   采用配对差分与方向对齐法：首先，利用 ESD 数据集“同一句子、不同情绪”的结构特性，对某A情绪（如“愤怒”）和中性情绪的 Embedding 配对相减，从而得到一系列pure的情绪增量向量；随后，计算这些增量向量的平均方向，并执行余弦一致性筛选，剔除那些与平均方向偏差过大的噪音向量，（可能需要观察具体余弦不同值后确认一个界限）确保只保留代表该情绪共性方向的核心特征；最后，对筛选后的向量进行模长统一化后求平均，获得该情绪的标准化纯情绪方向向量 **$\vec{V}_{Pure}$**，并通过计算不同情绪 **$\vec{V}_{Pure}$** 之间的余弦相似度矩阵，来量化情绪间的几何关系。对其他情绪相似操作，最后得到与A情绪方向差距最大的B情绪作为其对面情绪。
2. 调整“模态权重”，强制模型聚焦语音情绪
   理论上，把α（情绪向量倍数）放大，确实可以提高重要性。但学长之前的实验里貌似体现的是，α越大反而越不明显。可能原因是，这个向量找的还是不太对，也许更严谨的方法可以成功（？存疑，待验证）或是因为向量过大，处理时会被层归一化，可以尝试增加数量，尝试：

   $$
   Input = [\text{EmoVec}, \text{EmoVec}, \dots, \text{EmoVec}, \text{TextEmbeds}]
   $$
3. 真实情况攻击应用路径

   * **Audio Adversarial Examples: Targeted Attacks on Speech-to-Text** (IEEE S&P Workshop 2018)
     ASR，通过添加微小扰动，使得系统将文本转换为攻击者选择的特定文本。
   * **Steering Llama 2 via Contrastive Activation Addition**
     方法类似。同样是向量操控，用向量加法控制LLM的高阶行为。BUT！如果向量加法可以直接改变文本，那么用这个方法来操控情绪的意义何在？所以我认为，我们的特点要聚焦在“隐蔽性”。可以通过语音转文字的形式，向用户输出文本内容，但是情绪部分动手脚，引导LLM幻觉甚至越狱。与难点2进行呼应，这份论文中主打空间重复，也就是α对应的方法，侧面说明方法可以尝试。
   * **Multimodal Transformer for Unaligned Multimodal Language Sequences**
     数据流变长（时间上的叠加），可以造成模型性能的减弱
   * **Root Mean Square Layer Normalization**
     指出了RMSNorm的数学特性就是对输入特征的缩放是不敏感的，实验的结果也佐证了这一点，因此靠alpha的缩放不合适。

   如果情绪色轮不成功，通过寻找能够产生高熵，混乱效果的情绪向量。迫使LLM在处理特定任务时生成参数（temperature）被操控。比如，强烈情绪+高推理要求可能导致模型推理能力下降。（可能只能靠大量尝试，或借鉴论文）

   如果情绪色轮成功，可以通过把情绪改成与之方向差别最大的。。。。。（讨论中提到）

**总结：周末我要干的事**

* 尝试1中的实验，是否与假设一致
* 继续学习论文
* 想更多现实攻击路径
