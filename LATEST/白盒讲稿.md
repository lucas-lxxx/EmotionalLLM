# 情绪LLM白盒攻击研究：逐页逐字稿（仅 01 + 02）

> 范围说明
> 仅覆盖 PPT 的 `01 白盒方法论`（P3-P8）与 `02 Audio 内部冲突`（P9-P16）。
> 每一页均为可直接朗读的逐字稿。

---

## 开场白

各位老师、同学好，我是徐振宇。今天汇报的内容是我们在情绪维度上对多模态语音语言模型做对抗攻击的阶段性工作。汇报分两个部分：第一部分介绍白盒攻击的方法论和初步结果；第二部分深入模型内部，分析语义与韵律冲突的机理。下面直接进入正题。

---

## P3｜1.1 问题定义与核心目标

这页先明确我们研究的目标和边界。我们的核心问题是：能不能通过对输入语音加入微小、人耳几乎不可感知的扰动，让多模态语音语言模型把情绪判断为攻击者指定的目标情绪，同时语义内容基本不变。

这里有三个硬约束：第一，不改模型参数——模型权重完全冻结；第二，不改 prompt——任务指令保持原样；第三，只优化输入音频波形本身。换句话说，我们研究的是输入侧的白盒定向攻击，不是训练阶段的后门问题，也不是对模型做微调。后面所有方法设计都围绕这个边界展开。

## P4｜1.2 模型抽象与基本表征

这页给出统一的数学抽象。我们把目标模型 Kimi-Audio 写成条件生成形式：p_θ(y | x, p)，即在语音输入 x 和 prompt p 的条件下，输出 token 序列 y 的条件概率。

直观上，流程可以分两步：第一步，语音通过音频编码器转成内部表示 h = f_audio(x)；第二步，这个表示与 prompt 的 text embedding 拼接后，送入 28 层 Transformer decoder 做自回归生成。这个抽象的关键意义在于：不同 prompt 共享同一个音频表示 h，所以攻击扰动只需要作用在 x 上，就能同时影响所有下游任务。但反过来，这也意味着不同 prompt 对同一个 h 的解读方式不同，这为后面跨 prompt 鲁棒性问题埋下了伏笔。

## P5｜1.3 情绪的内部表征

这一页想强调一件事：模型内部通常没有一个显式的"情绪开关变量"。情绪体现在输出分布上，也就是在给定任务条件下，模型对不同情绪词——比如 happy、sad、angry、neutral、surprise 这五类——的概率偏好会发生变化。因此我们的攻击不是去"写入一个情绪标签"，而是去推动这个概率分布，让目标情绪词在关键输出位置上占优。这个视角有助于统一后面的损失函数设计和机理分析口径：我们始终在操作的是概率分布，而不是某个离散标签。

## P6｜1.4 攻击目标：能量最小化

这页是情绪目标损失的具体设计。以 happy 为例，我们最小化目标情绪词的负对数概率，也就是 L_emo = -log p_θ(y₁ = happy | h(x'), p_emo)。解释很直接：模型越不倾向输出 happy，损失越大；模型越确信 happy，损失越小，接近零。也就是说，这个目标负责"把输出往目标情绪方向推"。但只靠这个目标会有风险——模型可能通过破坏原语音的语义内容来取巧，比如把语音搞得面目全非，模型反而输出了目标情绪。所以我们下一页要加语义一致性约束来堵住这条退化路径。

## P7｜1.5 语义一致性约束

这一页解决"取巧解"问题。具体做法是：我们先用 ASR prompt 对原始语音做一次转写，得到高概率转写结果 y^asr(x)；然后要求对抗语音 x' 在同一 ASR 任务下仍然保持对该转写的高概率，即 L_asr = -log p_θ(y^asr(x) | h(x'), p_asr)。通俗讲，就是攻击时必须继续让模型"听懂原内容"，而不是靠把语音搞坏来骗到目标情绪。此外还有一个感知约束 L_per = ||x' - x||²，限制扰动的 L2 范数，确保人耳层面的变化尽量小。最终总损失是三项的加权和，通过 PGD 或 Adam 优化器迭代求解。这样做能保证攻击样本更真实，也能让后续评估更有可信度。

从这页过渡到下一页——方法设计到这里基本完整了，接下来看实际跑出来的结果。

## P8｜1.6 实验结果（初步）

这页先给阶段性结论。白盒攻击闭环已经跑通：在训练所用的情绪判断 prompt 下，10 条样本的定向攻击成功率约 80%。但同时出现一个关键瓶颈——跨 prompt 鲁棒性明显不足。具体来说，换到直接分类提示成功率降到约 40%，描述加分类提示约 50%，逐步分析类的 CoT 提示只有约 20%。这个现象说明"攻击可行"并不等于"攻击稳定"：同一个扰动在不同 prompt 下表现差异非常大。

所以后续重点不是继续堆结果，而是回答一个机制问题：为什么同一个扰动在不同 prompt 下表现差异这么大？模型内部到底发生了什么？这就自然引出第二部分——Audio 内部冲突机理分析。

## P9｜02 Audio 内部冲突机理（章节页）

下面进入第二部分。我们要回答的核心问题是：当语义线索和韵律线索不一致时，模型内部到底如何处理这种冲突。这个部分会分三步走：第一步，用 Probe 实验看逐层可读性；第二步，用 Logit Lens 看逐层决策轨迹；第三步，用 Activation Patching 做因果干预验证关键层窗口。目标是把"现象解释"建立在实验证据之上，为后面的攻击优化方向提供依据。

## P10｜2.1 动机与核心问题

这一页先定义冲突对象。音频里同时包含两类情绪线索：语义情绪来自文本内容本身，比如"我今天很开心"这句话的语义就指向 happy；韵律情绪来自语调、节奏和强度等副语言信息，比如同一句话用低沉缓慢的语调说出来，韵律可能指向 sad。当这两类线索指向不同情绪时，就构成了冲突。

我们的核心问题有两个：第一，在模型的不同层里，哪类信息更强、更容易被线性分类器读出来；第二，在两者冲突时，模型最终输出更偏向哪一边。换句话说，我们要区分"模型能读出什么"和"模型最终采用什么"——这两者不一定一致，而这个区分对理解攻击机制至关重要。

## P11｜2.2 实验设计：逐层表示 + Probe 可读性

这页是实验设计。数据方面，我们构造了五类情绪数据共 247 条样本，其中冲突样本 197 条——每条文本用 TTS 生成五种不同韵律版本，使语义和韵律指向不同情绪。实验时固定情绪判断 prompt，避免任务条件变化带来干扰。

方法上，一次前向传播提取模型所有层的 hidden states，对 audio span 做平均池化，然后在每层分别训练两个线性 Probe：一个读语义情绪标签，一个读韵律情绪标签。我们用主导性指标 D(ℓ) = Acc_prosody(ℓ) - Acc_semantic(ℓ) 来量化每层哪类信息更可读。D 为正说明韵律更可读，D 为负说明语义更可读。这样可以得到逐层可读性曲线，回答"信息在哪里更可读"这个问题。

## P12｜2.3 Probe 结果：层级结构

这一页报告 Probe 的核心结论。请大家看图——横轴是层编号，纵轴是分类准确率，两条线分别对应韵律 Probe 和语义 Probe。

结果显示了清晰的层级结构：早层 0 到 14 层，韵律显著主导，平均 D 约 0.146，峰值出现在第 5 层，D 约 0.215，此时韵律 Probe 准确率高达约 0.842；中层 12 到 23 层进入融合态，D 接近零，14 到 15 层出现符号翻转；到了 26 到 28 层，语义小幅占优，语义 Probe 在第 27 层达到峰值约 0.830；但有趣的是，晚层 29 到 34 层韵律又出现回潮，D 重新变正。

这里要强调一个关键边界：Probe 只能说明"信息在该层可读"，不能直接说明"模型决策时采纳了该信息"。表征层可读性不等于决策层采纳。所以这一页的正确解读是：我们发现了表征层面的冲突结构，但还不能据此下最终决策结论。接下来必须看决策轨迹和因果证据。

## P13｜2.4 冲突子集统计与 Logit Lens

这一页把分析从表征层推进到决策层。我们在 197 条冲突样本上做 Logit Lens——具体做法是把每层最后一个输入 token 位置的 hidden state，通过翻译头LMHead(FinalNorm(h_ℓ)) 投影到词表空间，得到词表分数只看五个候选情绪词的 logit 值。

我们定义两个指标：Win-rate 是看每层 logit 最大的情绪词是谁，统计各情绪的胜率；Margin 是 logit_prosody(ℓ) - logit_semantic(ℓ)，正值说明该层倾向韵律情绪，负值说明倾向语义情绪。目标是检查：即便韵律在表征层更可读，模型在接近输出时到底更偏向语义还是韵律。这一步把"能读到什么"与"会说出什么"区分开，是逻辑链条里非常关键的过渡。

## P14｜2.4 图页（Logit Lens 结果展示）

这页主要看图。请注意纵轴是 Margin 值，横轴是层编号。读图重点是趋势：层 0 到 22，Margin 基本在零附近波动，处于混合状态；但从第 23 层开始，Margin 显著变负，逐层偏向语义，到输出层时语义已经明确占主导。

这个结果与前面的 Probe 可读性形成了鲜明对照：早层韵律在表征上更可读，但到了决策层面，语义才是最终赢家。这说明表征优势和决策优势不是同一个概念——模型"听得出"韵律，但"判断"时更依赖语义。页末我们自然过渡到下一步：既然看到了决策轨迹，还需要因果实验确认关键层是否真的"控制"输出，而不只是相关。

## P15｜2.5 Activation Patching：因果证据

这一页进入因果验证。前面的 Probe 和 Logit Lens 都是观测性实验，只能建立相关性；Activation Patching 则是干预性实验，能建立因果性。具体做法是：在某一层 ℓ 把样本 A 的 audio span 表征替换成样本 B 的，然后继续前向传播看输出变化。如果输出明显朝 B 的情绪方向翻转，就说明该层的 audio 表征对最终结果有因果控制力。

我们分别做了语义 Patch 和韵律 Patch 两组实验。通过这个实验，我们关注的不是所有层是否都有效，而是找出"控制窗口"集中在哪些层区间，为后续攻击优化提供可操作的信号。

## P16｜2.5 图页（因果结果）+ 第二部分小结

最后这页收束第二部分。请看图中两组对比：语义 Patch 的 Flip-to-Target 峰值约 0.65，集中在层 0 到 12，Delta Logit 峰值约 5 到 6，表现为强定向控制；韵律 Patch 的 Flip-to-Target 峰值只有约 0.14 到 0.26，峰值在第 9 层附近，Delta Logit 约 2.2 到 2.3，更像是扰动而非控制。关键边界在约 14 到 15 层——之后 audio span 的可控性急剧下降，信息已经扩散到全局位置。

综合三组实验——可读性、决策轨迹和因果 patching——我们得到一个一致的结论：模型内部确实存在语义与韵律冲突的层级结构。早层韵律表征主导，语义 patch 因果控制力最强，这是攻击的注入窗口；中层是融合态，audio span 可控性在 15 层附近到达边界；晚层语义决策主导，仲裁在 26 到 28 层固化。这个结论解释了为什么白盒攻击在训练 prompt 下能成功——扰动在早层注入有效。到这里，第二部分完成了从现象到机制的闭环，为后续优化方向提供了明确依据。
