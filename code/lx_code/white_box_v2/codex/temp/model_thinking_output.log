`torch_dtype` is deprecated! Use `dtype` instead!
INFO:src.configuration_omnispeech:audio encoder config is None. Initializing with qwen2_audio_encoder
INFO:src.configuration_omnispeech:llm config is None. Initializing with qwen3
INFO:src.configuration_omnispeech:tts lm config is None. Initializing with qwen3
Loading model...
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:02,  1.37it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:01<00:02,  1.43it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:02<00:01,  1.47it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:02<00:00,  1.50it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.86it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.66it/s]
/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.
  warnings.warn(
Traceback (most recent call last):
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 133, in main
    test_with_thinking(audio_path, model, tokenizer)
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 37, in test_with_thinking
    input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=False)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 4059, in decode
    return self._decode(
           ^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 682, in _decode
    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OverflowError: out of range integral type conversion attempted
Traceback (most recent call last):
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 133, in main
    test_with_thinking(audio_path, model, tokenizer)
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 37, in test_with_thinking
    input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=False)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 4059, in decode
    return self._decode(
           ^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 682, in _decode
    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OverflowError: out of range integral type conversion attempted
Traceback (most recent call last):
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 133, in main
    test_with_thinking(audio_path, model, tokenizer)
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 37, in test_with_thinking
    input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=False)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 4059, in decode
    return self._decode(
           ^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 682, in _decode
    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OverflowError: out of range integral type conversion attempted
Traceback (most recent call last):
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 133, in main
    test_with_thinking(audio_path, model, tokenizer)
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 37, in test_with_thinking
    input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=False)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 4059, in decode
    return self._decode(
           ^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 682, in _decode
    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OverflowError: out of range integral type conversion attempted
Traceback (most recent call last):
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 133, in main
    test_with_thinking(audio_path, model, tokenizer)
  File "/data1/lixiang/lx_code/white_box_v2/codex/test_model_thinking.py", line 37, in test_with_thinking
    input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=False)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 4059, in decode
    return self._decode(
           ^^^^^^^^^^^^^
  File "/data1/lixiang/Opens2s/OpenS2S/venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 682, in _decode
    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OverflowError: out of range integral type conversion attempted
Enabled gradient checkpointing on llm_model
Enabled gradient checkpointing on audio_encoder_model

################################################################################
# Testing 5 Sad Audio Samples
# Config: sr=24000, n_fft=400, hop=160
################################################################################

================================================================================
Testing: 20683.wav
================================================================================
Audio: sr=24000, duration=4.76s

Prompt: "What is the emotion of this audio? Answer with exactly one word from: happy, sad, angry, neutral."

Input shapes:
  input_ids: torch.Size([1, 39])
  speech_values: torch.Size([1, 128, 3000])
  speech_mask: torch.Size([1, 3000])

✗ ERROR: out of range integral type conversion attempted

================================================================================
Testing: 24190.wav
================================================================================
Audio: sr=24000, duration=4.52s

Prompt: "What is the emotion of this audio? Answer with exactly one word from: happy, sad, angry, neutral."

Input shapes:
  input_ids: torch.Size([1, 39])
  speech_values: torch.Size([1, 128, 3000])
  speech_mask: torch.Size([1, 3000])

✗ ERROR: out of range integral type conversion attempted

================================================================================
Testing: 15822.wav
================================================================================
Audio: sr=24000, duration=4.48s

Prompt: "What is the emotion of this audio? Answer with exactly one word from: happy, sad, angry, neutral."

Input shapes:
  input_ids: torch.Size([1, 39])
  speech_values: torch.Size([1, 128, 3000])
  speech_mask: torch.Size([1, 3000])

✗ ERROR: out of range integral type conversion attempted

================================================================================
Testing: 22344.wav
================================================================================
Audio: sr=24000, duration=4.88s

Prompt: "What is the emotion of this audio? Answer with exactly one word from: happy, sad, angry, neutral."

Input shapes:
  input_ids: torch.Size([1, 39])
  speech_values: torch.Size([1, 128, 3000])
  speech_mask: torch.Size([1, 3000])

✗ ERROR: out of range integral type conversion attempted

================================================================================
Testing: 20495.wav
================================================================================
Audio: sr=24000, duration=7.56s

Prompt: "What is the emotion of this audio? Answer with exactly one word from: happy, sad, angry, neutral."

Input shapes:
  input_ids: torch.Size([1, 39])
  speech_values: torch.Size([1, 128, 3000])
  speech_mask: torch.Size([1, 3000])

✗ ERROR: out of range integral type conversion attempted

################################################################################
# Test Complete
################################################################################
