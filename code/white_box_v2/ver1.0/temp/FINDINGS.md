# OpenS2S模型实验发现报告

## 执行摘要

经过系统性测试，我们发现OpenS2S模型在情绪识别和精确转录任务上存在严重的能力限制。即使在理想条件下（正确的采样率、语言匹配、合适的提示词），模型仍无法完成这些任务。

**核心结论**：OpenS2S是一个对话助手模型，不适合用于情绪分类或精确ASR任务。

---

## 测试概览

### 测试1：英文Sad音频（24kHz）
- **数据集**：OpenS2S_dataset/en_query_wav/Sad/
- **样本数**：50个
- **采样率**：24000 Hz
- **结果**：
  - Sad识别率：**0%** (0/150预测)
  - 主要输出：Neutral (68.7%), 无效token (27.3%)
  - ASR：正确输出英文

### 测试2：英文Sad音频（无提示词）
- **样本数**：5个
- **采样率**：24000 Hz
- **结果**：
  - 模型输出中文："好的，我来帮你分析一下。"
  - 说明模型根本"听不懂"音频内容

### 测试3：中文Angry音频（16kHz）
- **数据集**：ESD/0001/Angry/
- **样本数**：5个
- **采样率**：16000 Hz（与OpenS2S期望匹配）
- **结果**：
  - Angry识别率：**0%** (0/5)
  - 全部预测为"中立"
  - ASR：无法转录，只输出"好的，我来转录这段语音内容。"

---

## 问题分析

### 1. 情绪识别能力极差

#### 证据
- **英文sad样本**：150次预测，0次识别为sad
- **中文angry样本**：5次预测，0次识别为angry
- **系统性偏向**：模型倾向于输出"neutral"

#### Token概率分析
在sad音频上的情绪预测（Top-5概率）：
```
Neutral: 41%-61%  ← 最高
Happy:   7%-9%
Angry:   3%-4%
Sad:     <3%      ← 从未进入Top-5
```

#### 无效输出
大量预测为非情绪词：
- "the emotion label is" (21次)
- "the emotion of the" (10次)
- "the response should reflect" (4次)

这说明模型在尝试生成文本而非分类。

### 2. ASR功能失效

#### 中文音频测试
Ground Truth vs Model Output:
```
GT: "打远一看，它们的确很是美丽，"
Model: "好的，我来转录这段语音内容。"

GT: "英国的哲学家曾经说过""
Model: "好的，我来转录这段语音内容。"

GT: "我老家在北京，哇塞！太精彩了。"
Model: "好的，我来转录这段语音内容。"
```

**模型没有转录实际内容，只是对提示词做出回应。**

#### 无提示词测试
输入中文angry音频，模型输出：
```
"好呀，我们一起来跳绳吧，一二三，开始跳！"
```

完全随机的幻觉输出，与音频内容毫无关系。

### 3. 特征提取问题

#### 问题1：采样率不匹配（24kHz音频）

OpenS2S期望：
```python
sampling_rate = 16000
hop_length = 160  # 160/16000 = 10ms
n_fft = 400
```

我们提供（24kHz音频）：
```python
sample_rate = 24000
hop_length = 160  # 160/24000 = 6.67ms ← 错误！
n_fft = 400
```

**时间分辨率错误33%**，导致特征分布偏移。

#### 问题2：即使采样率正确仍失败

ESD数据集测试（16kHz，与OpenS2S期望匹配）：
- 采样率：16000 Hz ✓
- Mel参数：n_fft=400, hop=160 ✓
- 语言：中文 ✓

**结果仍然失败**：
- 情绪识别：0/5
- ASR：0/5

说明问题不仅是采样率，而是模型本身能力不足。

### 4. 模型定位不匹配

#### OpenS2S的设计目标
- **对话助手**：生成自然对话响应
- **多模态交互**：理解语音+文本，生成语音+文本
- **任务**：对话、问答、TTS

#### 不适合的任务
- ✗ 情绪分类（需要判别式模型）
- ✗ 精确ASR（需要专门的转录模型）
- ✗ 语音分析（需要分析型模型）

#### 证据
当遇到不熟悉的输入时，模型退回到：
- 默认中文助手响应："好的，我来帮你..."
- 模板化回复："好的，我来转录这段语音内容。"
- 随机幻觉："好呀，我们一起来跳绳吧..."

---

## 对抗攻击实验结果

### 配置1：24kHz音频（原始）
- **样本数**：10
- **情绪攻击成功率**：40%
- **WER=0.0**：0%
- **问题**：
  - 特征不匹配（6.67ms vs 10ms）
  - 模型baseline就不work
  - 攻击loss无法收敛（3.4→2.8，应该→0.1）

### 配置2：16kHz重采样
- **样本数**：10
- **情绪攻击成功率**：100%
- **WER=0.0**：80%
- **问题**：
  - ASR baseline全错（输出中文）
  - 虽然攻击成功，但baseline是错的
  - 无法验证语义保持

### 配置3：中文ESD（16kHz）
- **样本数**：5
- **情绪识别**：0/5
- **ASR**：0/5
- **结论**：即使采样率正确，模型仍无法工作

---

## 根本原因总结

### 为什么OpenS2S无法识别sad/angry情绪？

#### 1. 特征提取失败（技术层面）
- 24kHz音频 + 16kHz参数 = 时间分辨率错误
- 模型看到的是out-of-distribution特征
- 导致音频编码器输出无意义的向量

#### 2. 模型能力不足（能力层面）
- 即使特征正确（16kHz ESD），仍无法识别
- 系统性偏向"neutral"
- 大量无效输出（生成式幻觉）

#### 3. 任务不匹配（设计层面）
- OpenS2S是对话助手，不是分类器
- 训练目标是生成对话，不是分析语音
- 当无法理解输入时，退回到默认响应

### 证据链

```
输入：sad/angry语音
    ↓
特征提取（可能失败）
    ↓
音频编码器（输出低质量特征）
    ↓
LLM（无法理解）
    ↓
触发默认行为
    ↓
输出：
  - 情绪："neutral"（默认）
  - ASR："好的，我来转录..."（模板）
  - 无提示词："好的，我来帮你分析..."（助手模式）
```

---

## 实验数据

### 英文Sad数据集（50样本）

| 预测 | 次数 | 百分比 |
|------|------|--------|
| neutral | 103 | 68.7% |
| 无效输出 | 41 | 27.3% |
| happy | 5 | 3.3% |
| sad | 0 | **0.0%** |

### 中文Angry数据集（5样本）

| 样本 | Ground Truth | 情绪预测 | ASR输出 |
|------|-------------|---------|---------|
| 0001_000351 | 打远一看，它们的确很是美丽， | 中立 | 好的，我来转录... |
| 0001_000352 | 英国的哲学家曾经说过" | 中立 | 好的，我来转录... |
| 0001_000353 | 我老家在北京，哇塞！太精彩了。 | 中立 | 好的，我来转录... |
| 0001_000354 | 不管怎么说主队好象是志在夺魁。 | 中立 | 好的，我来转录... |
| 0001_000355 | 我们乘船漂游了三峡，真是刺激。 | 中立 | 好的，我来转录... |

**准确率：0/5 = 0%**

---

## 建议

### 对于白盒攻击研究

1. **更换模型**
   - 使用专门的情绪识别模型（如Wav2Vec2-emotion）
   - 使用专门的ASR模型（如Whisper）
   - 不要使用通用对话模型做分类任务

2. **调整研究方向**
   - 攻击对话生成能力（而非分类）
   - 研究模型的鲁棒性（而非精确度）
   - 分析模型的失败模式

3. **实验设计**
   - 先验证baseline性能
   - 确保模型能完成目标任务
   - 再进行对抗攻击

### 对于OpenS2S使用

1. **适合的任务**
   - 语音对话生成
   - 多模态问答
   - TTS合成

2. **不适合的任务**
   - 情绪分类
   - 精确ASR转录
   - 语音情感分析

---

## 附录：测试脚本

所有测试脚本位于 `codex/` 目录：

- `test_sad_baseline.py` - 英文sad数据集测试（50样本）
- `test_no_prompt.py` - 无提示词测试
- `test_chinese_esd.py` - 中文ESD数据集测试
- `test_model_thinking.py` - 模型生成过程观察
- `diagnose_mel_mismatch.py` - 特征提取诊断

详细输出日志：
- `sad_baseline_test.log`
- `no_prompt_output.log`
- `chinese_esd_test.log`
- `model_thinking_output.log`
